{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "745197b1-1983-4730-8fbc-ef37ad7dcfbe",
   "metadata": {},
   "source": [
    "# This is a Spam mail detection project\n",
    "# we are going to classify from the dataset contain with spam and Ham which email is Spam or ham\n",
    "# 1-Problem defination\n",
    "# 2-Dataset\n",
    "# 3-Evaluation\n",
    "# 4-Features\n",
    "# 5-Modelling\n",
    "# 6-Experimentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3f3206-3d8e-455f-bb00-0e3566b810a5",
   "metadata": {},
   "source": [
    "# 1-Problem defination\n",
    "    based on the given data we need to predict which email is Spam or not spam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ce5dc1-72cc-4eff-b313-e65fa562b32a",
   "metadata": {},
   "source": [
    "# 2- Dataset\n",
    "    We have the data and already have loaded it\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca99cc0-506a-4be7-95b1-b03989e15565",
   "metadata": {},
   "source": [
    "# 3-Evaluate\n",
    "    In initial stages we need to make sure if our model gave us the accuracy of about 95%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cfc128b-e5ca-4a78-9b92-19d7742a3e31",
   "metadata": {},
   "source": [
    "# 4-Features\n",
    "    what feature are important and what feature column means what?\n",
    "    label\r",
    "    \n",
    "Labels of Emails which can be either Spam or Ham\r",
    "    \n",
    "\r\n",
    "te    xt\r\n",
    "Emails da    ta\r\n",
    "\r\n",
    "labe    l_num\r\n",
    "if spam it's 1, or else it's 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92d93e52-332e-4856-8daf-5a9185e5e6c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\bilal\\desktop\\ml_project\\spam_filter_project\\env\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: click in c:\\users\\bilal\\desktop\\ml_project\\spam_filter_project\\env\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\bilal\\desktop\\ml_project\\spam_filter_project\\env\\lib\\site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\bilal\\desktop\\ml_project\\spam_filter_project\\env\\lib\\site-packages (from nltk) (2024.4.16)\n",
      "Requirement already satisfied: tqdm in c:\\users\\bilal\\desktop\\ml_project\\spam_filter_project\\env\\lib\\site-packages (from nltk) (4.66.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\bilal\\desktop\\ml_project\\spam_filter_project\\env\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "002afbba-1e65-4da8-8d8f-4253bbdfcb5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn in c:\\users\\bilal\\desktop\\ml_project\\spam_filter_project\\env\\lib\\site-packages (0.13.2)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in c:\\users\\bilal\\desktop\\ml_project\\spam_filter_project\\env\\lib\\site-packages (from seaborn) (1.24.3)\n",
      "Requirement already satisfied: pandas>=1.2 in c:\\users\\bilal\\desktop\\ml_project\\spam_filter_project\\env\\lib\\site-packages (from seaborn) (2.1.4)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in c:\\users\\bilal\\desktop\\ml_project\\spam_filter_project\\env\\lib\\site-packages (from seaborn) (3.8.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\bilal\\desktop\\ml_project\\spam_filter_project\\env\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\bilal\\desktop\\ml_project\\spam_filter_project\\env\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\bilal\\desktop\\ml_project\\spam_filter_project\\env\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\bilal\\desktop\\ml_project\\spam_filter_project\\env\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\bilal\\desktop\\ml_project\\spam_filter_project\\env\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\bilal\\desktop\\ml_project\\spam_filter_project\\env\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (10.0.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\bilal\\desktop\\ml_project\\spam_filter_project\\env\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\bilal\\desktop\\ml_project\\spam_filter_project\\env\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\bilal\\desktop\\ml_project\\spam_filter_project\\env\\lib\\site-packages (from pandas>=1.2->seaborn) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\bilal\\desktop\\ml_project\\spam_filter_project\\env\\lib\\site-packages (from pandas>=1.2->seaborn) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\bilal\\desktop\\ml_project\\spam_filter_project\\env\\lib\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c62b26a9-77b0-488b-afca-23376088fd78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wordcloud in c:\\users\\bilal\\desktop\\ml_project\\spam_filter_project\\env\\lib\\site-packages (1.9.3)\n",
      "Requirement already satisfied: numpy>=1.6.1 in c:\\users\\bilal\\desktop\\ml_project\\spam_filter_project\\env\\lib\\site-packages (from wordcloud) (1.24.3)\n",
      "Requirement already satisfied: pillow in c:\\users\\bilal\\desktop\\ml_project\\spam_filter_project\\env\\lib\\site-packages (from wordcloud) (10.0.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\bilal\\desktop\\ml_project\\spam_filter_project\\env\\lib\\site-packages (from wordcloud) (3.8.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\bilal\\desktop\\ml_project\\spam_filter_project\\env\\lib\\site-packages (from matplotlib->wordcloud) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\bilal\\desktop\\ml_project\\spam_filter_project\\env\\lib\\site-packages (from matplotlib->wordcloud) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\bilal\\desktop\\ml_project\\spam_filter_project\\env\\lib\\site-packages (from matplotlib->wordcloud) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\bilal\\desktop\\ml_project\\spam_filter_project\\env\\lib\\site-packages (from matplotlib->wordcloud) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\bilal\\desktop\\ml_project\\spam_filter_project\\env\\lib\\site-packages (from matplotlib->wordcloud) (23.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\bilal\\desktop\\ml_project\\spam_filter_project\\env\\lib\\site-packages (from matplotlib->wordcloud) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\bilal\\desktop\\ml_project\\spam_filter_project\\env\\lib\\site-packages (from matplotlib->wordcloud) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\bilal\\desktop\\ml_project\\spam_filter_project\\env\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->wordcloud) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "701277e6-db38-4a47-92f8-89fc416e9f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import numpy as np                                                    # For numerical operations\n",
    "import pandas as pd                                                   # For data manipulation and analysis\n",
    "import string                                                         # Filter out all of the puncuation from the email text\n",
    "\n",
    "\n",
    "import nltk                                                           # we need have to download something\n",
    "# Importing NLTK libraries for text preprocessing\n",
    "from nltk.corpus import stopwords                                     # For accessing a list of common stopwords\n",
    "from nltk.stem.porter import PorterStemmer                            # For stemming words to their root forms\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer           # For converting text data into numerical feature vectors\n",
    "from sklearn.model_selection import train_test_split                  # For splitting data into training and testing sets\n",
    "\n",
    "\n",
    "# For building a random forest classifier model\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2a420f50-6d4a-49d5-acda-92ea80f40731",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Bilal\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Downloading NLTK's stopwords corpus\n",
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e18519d7-a996-4b4f-bd18-66ad0f6abe24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the dataset from a CSV file into a pandas DataFrame\n",
    "df = pd.read_csv('spam_ham_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4a85e80f-006a-4b36-b479-0aaf5ff9b68e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>label_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>605</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: enron methanol ; meter # : 988291 thi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2349</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: hpl nom for january 9 , 2001 ( see at...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3624</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: neon retreat ho ho ho , we ' re aroun...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4685</td>\n",
       "      <td>spam</td>\n",
       "      <td>Subject: photoshop , windows , office . cheap ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2030</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: re : indian springs this deal is to b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 label                                               text  \\\n",
       "0         605   ham  Subject: enron methanol ; meter # : 988291 thi...   \n",
       "1        2349   ham  Subject: hpl nom for january 9 , 2001 ( see at...   \n",
       "2        3624   ham  Subject: neon retreat ho ho ho , we ' re aroun...   \n",
       "3        4685  spam  Subject: photoshop , windows , office . cheap ...   \n",
       "4        2030   ham  Subject: re : indian springs this deal is to b...   \n",
       "\n",
       "   label_num  \n",
       "0          0  \n",
       "1          0  \n",
       "2          0  \n",
       "3          1  \n",
       "4          0  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "900c8381-1fa3-40c0-af40-e38808dcf24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing newline characters '\\r\\n' from the 'text' column and replacing them with spaces\n",
    "df['text'] = df['text'].apply(lambda x: x.replace('\\r\\n', ' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8fa4eb95-50e4-4a02-af91-53299ffcfaa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>label_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5166</th>\n",
       "      <td>1518</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: put the 10 on the ft the transport vo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5167</th>\n",
       "      <td>404</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: 3 / 4 / 2000 and following noms hpl c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5168</th>\n",
       "      <td>2933</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: calpine daily gas nomination &gt; &gt; juli...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5169</th>\n",
       "      <td>1409</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: industrial worksheets for august 2000...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5170</th>\n",
       "      <td>4807</td>\n",
       "      <td>spam</td>\n",
       "      <td>Subject: important online banking alert dear v...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0 label                                               text  \\\n",
       "5166        1518   ham  Subject: put the 10 on the ft the transport vo...   \n",
       "5167         404   ham  Subject: 3 / 4 / 2000 and following noms hpl c...   \n",
       "5168        2933   ham  Subject: calpine daily gas nomination > > juli...   \n",
       "5169        1409   ham  Subject: industrial worksheets for august 2000...   \n",
       "5170        4807  spam  Subject: important online banking alert dear v...   \n",
       "\n",
       "      label_num  \n",
       "5166          0  \n",
       "5167          0  \n",
       "5168          0  \n",
       "5169          0  \n",
       "5170          1  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "175e1ba5-80f8-4485-a521-6b1b7371dff4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Subject: enron methanol ; meter # : 988291 this is a follow up to the note i gave you on monday , 4 / 3 / 00 { preliminary flow data provided by daren } . please override pop ' s daily volume { presently zero } to reflect daily activity you can obtain from gas control . this change is needed asap for economics purposes .\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accessing the text from the first row of the 'text' column in the DataFrame\n",
    "df.text.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "262ab6d8-5d86-4b4f-a54a-09c8516ad69b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Subject: hpl nom for january 9 , 2001 ( see attached file : hplnol 09 . xls ) - hplnol 09 . xls'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accessing the text from the second row of the 'text' column in the DataFrame\n",
    "df.text.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "30b1e5fb-3a14-4c4e-a260-ba20997c8e14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Subject: neon retreat ho ho ho , we ' re around to that most wonderful time of the year - - - neon leaders retreat time ! i know that this time of year is extremely hectic , and that it ' s tough to think about anything past the holidays , but life does go on past the week of december 25 through january 1 , and that ' s what i ' d like you to think about for a minute . on the calender that i handed out at the beginning of the fall semester , the retreat was scheduled for the weekend of january 5 - 6 . but because of a youth ministers conference that brad and dustin are connected with that week , we ' re going to change the date to the following weekend , january 12 - 13 . now comes the part you need to think about . i think we all agree that it ' s important for us to get together and have some time to recharge our batteries before we get to far into the spring semester , but it can be a lot of trouble and difficult for us to get away without kids , etc . so , brad came up with a potential alternative for how we can get together on that weekend , and then you can let me know which you prefer . the first option would be to have a retreat similar to what we ' ve done the past several years . this year we could go to the heartland country inn ( www . . com ) outside of brenham . it ' s a nice place , where we ' d have a 13 - bedroom and a 5 - bedroom house side by side . it ' s in the country , real relaxing , but also close to brenham and only about one hour and 15 minutes from here . we can golf , shop in the antique and craft stores in brenham , eat dinner together at the ranch , and spend time with each other . we ' d meet on saturday , and then return on sunday morning , just like what we ' ve done in the past . the second option would be to stay here in houston , have dinner together at a nice restaurant , and then have dessert and a time for visiting and recharging at one of our homes on that saturday evening . this might be easier , but the trade off would be that we wouldn ' t have as much time together . i ' ll let you decide . email me back with what would be your preference , and of course if you ' re available on that weekend . the democratic process will prevail - - majority vote will rule ! let me hear from you as soon as possible , preferably by the end of the weekend . and if the vote doesn ' t go your way , no complaining allowed ( like i tend to do ! ) have a great weekend , great golf , great fishing , great shopping , or whatever makes you happy ! bobby\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accessing the text from the third row of the 'text' column in the DataFrame\n",
    "df.text.iloc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fefa18da-37ac-4bd9-b3fc-2d43d6f4eb9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5171 entries, 0 to 5170\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   Unnamed: 0  5171 non-null   int64 \n",
      " 1   label       5171 non-null   object\n",
      " 2   text        5171 non-null   object\n",
      " 3   label_num   5171 non-null   int64 \n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 161.7+ KB\n"
     ]
    }
   ],
   "source": [
    "# Displaying summary information about the DataFrame\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fb1442b8-1075-40ac-b8db-7b0261966508",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing a Porter stemmer and creating a corpus of stemmed text data\n",
    "stemmer = PorterStemmer()                                                        # Initialize a Porter stemmer for word stemming\n",
    "corpus = []                                                                      # Initialize an empty list to store the processed text data\n",
    "\n",
    "stopwords_set = set(stopwords.words('english'))                                  # Get a set of English stopwords\n",
    "\n",
    "# Iterate through each row of the DataFrame to preprocess the text data\n",
    "for i in range(len(df)):\n",
    "     # Convert the text to lowercase and tokenize it\n",
    "    text = df['text'].iloc[i].lower()\n",
    "    text = text.translate(str.maketrans(' ', ' ', string.punctuation)).split()\n",
    "    # Apply stemming to each word in the text and remove stopwords\n",
    "    text = [stemmer.stem(word) for word in text if word not in stopwords_set]\n",
    "    # Join the stemmed words back into a single string and add it to the corpus\n",
    "    text = ' '.join(text)\n",
    "    corpus.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9d8dc6d6-d57c-443b-ab36-ef4b2f747224",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'subject hpl nom januari 9 2001 see attach file hplnol 09 xl hplnol 09 xl'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accessing the preprocessed text data of the second document in the corpus\n",
    "corpus[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c0372e91-a2c0-44d8-b4b6-528bda05a3a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Subject: enron methanol ; meter # : 988291 this is a follow up to the note i gave you on monday , 4 / 3 / 00 { preliminary flow data provided by daren } . please override pop ' s daily volume { presently zero } to reflect daily activity you can obtain from gas control . this change is needed asap for economics purposes .\""
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.text.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c00a5f69-3836-4d0b-ba64-e528b3dc1206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating feature vectors using CountVectorizer and splitting the data into training and testing sets\n",
    "vectorizer = CountVectorizer()                                             # Initialize CountVectorizer for converting text to feature vectors\n",
    "x = vectorizer.fit_transform(corpus).toarray()                             # Convert text corpus to a matrix of token counts\n",
    "y = df.label_num                                                           # Assigning labels from the DataFrame to y\n",
    "\n",
    "# Splitting the data into training and testing sets with a ratio of 80% training and 20% testing\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size =0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d637b6f9-67e2-4637-9c2d-0d420a0d7d09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c79d0fa8-a2ea-46d2-918a-0ee8452f1d15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_train: (4136, 42637)\n",
      "Shape of y_train: (4136,)\n"
     ]
    }
   ],
   "source": [
    "# Printing the shapes of the training data and corresponding labels\n",
    "print(\"Shape of x_train:\", x_train.shape)                              # Print the shape of the training data\n",
    "print(\"Shape of y_train:\", y_train.shape)                              # Print the shape of the corresponding labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "70ac7ac1-1416-4c31-95f5-abbb6f213ef9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(n_jobs=-1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_jobs=-1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(n_jobs=-1)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initializing a RandomForestClassifier and fitting it to the training data\n",
    "clf = RandomForestClassifier(n_jobs=-1)                               # Initialize a RandomForestClassifier with parallel processing\n",
    "clf.fit(x_train, y_train)                                             # Fit the classifier to the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f6dfba69-1243-4b28-a2a5-ee35de5fc424",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9768115942028985"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculating the accuracy score of the trained classifier on the testing data\n",
    "clf.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ffe65935-0ad9-4ad0-8f3d-f7aec0d6897e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning the text of the 11th document in the DataFrame to the variable 'email_to_classify'\n",
    "email_to_classify = df.text.values[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c231eacc-f229-4770-bb4a-931083cb0e10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Subject: vocable % rnd - word asceticism vcsc - brand new stock for your attention vocalscape inc - the stock symbol is : vcsc vcsc will be our top stock pick for the month of april - stock expected to bounce to 12 cents level the stock hit its all time low and will bounce back stock is going to explode in next 5 days - watch it soar watch the stock go crazy this and next week . breaking news - vocalscape inc . announces agreement to resell mix network services current price : $ 0 . 025 we expect projected speculative price in next 5 days : $ 0 . 12 we expect projected speculative price in next 15 days : $ 0 . 15 vocalscape networks inc . is building a company that ' s revolutionizing the telecommunications industry with the most affordable phone systems , hardware , online software , and rates in canada and the us . vocalscape , a company with global reach , is receiving international attention for the development of voice over ip ( voip ) application solutions , including the award - winning eyefontm , a softphone for real - time pc - to - phone . we are an advanced implementer of pbx systems for companies , call centers , itsps and service providers . vocalscape has created software and interactive solutions revolving around global communications and data voice convergence . companies use vocalscape for voice over internet protocol applications like ip pbxs , softswitches , pc 2 phone and web 2 phone , providing real - time human interaction and information delivery over the internet . through vocalscape ' s solutions , businesses can offer a quality voice service to anywhere in the world at rates that are significantly lower than current long distance charges . we develop software to run voip networks , and sell , install and service our own branded voip gateways and gatekeeper control software . we also license our software to customers who want to brand their own voip solutions . vocalscape is committed to making great technology ; challenging the status quo , and building a 21 st century company that changes the way businesses communicate and interact through the internet . current price : $ 0 . 025 we expect projected speculative price in next 5 days : $ 0 . 12 we expect projected speculative price in next 15 days : $ 0 . 15 breaking news - vocalscape inc . announces agreement to resell mix network services - - - - - - - - - - katonah , n . y . , / prnewswire - firstcall via comtex / - - vocalscape , inc . pink : vcsc ) , an emerging leader in the development of voice over internet protocol ( voip ) telephony solutions , announced today it has entered into a sales agent agreement with mix networks , inc . a voip enhanced telephony service provider . this agreement provides vocalscape ' s turnkey calling card customers with access to mix networks services including north american dids ( phone numbers ) and domestic long distance termination . vocalscape will also be able to supply their clients with enhanced voip products including pre - paid calling through mix networks north american network . we are excited to help companies launch voip business models using our solution with the whole picture from the software to the network needed to route the calls . mix networks gives us the ability to offer wholesale monthly flat rate plans and dids to our clients that allow for us to build business models like popular voip companies such as vonage and packet 8 , says ryan gibson , vp vocalscape networks some legal words before you continue : information within this email contains forward looking statements within the meaning of section 27 a of the securities act of 1933 and section 21 b of the securities exchange act of 1934 . any statements that express or involve discussions with respect to predictions , goals , expectations , beliefs , plans , projections , objectives , assumptions or future events or performance are not statements of historical fact and may be forward looking statements . forward looking statements are based on expectations , estimates and projections at the time the statements are made that involve a number of risks and uncertainties which could cause actual results or events to differ materially from those presently anticipated . forward looking statements in this action may be identified through the use of words such as : projects , foresee , expects , estimates , believes , understands will , part of : anticipates , or that by statements indicating certain actions may , could , or might occur . all information provided within this email pertaining to investing , stocks , securities must be understood as information provided and not investment advice . emerging equity alert advises all readers and subscribers to seek advice from a registered professional securities representative before deciding to trade in stocks featured within this email . none of the material within this report shall be construed as any kind of investment advice . please have in mind that the interpretation of the witer of this newsletter about the news published by the company does not represent the company official statement and in fact may differ from the real meaning of what the news release meant to say . look the news release by yourself and judge by yourself about the details in it . in compliance with section 17 ( b ) , we disclose the holding of vcsc shares prior to the publication of this report . be aware of an inherent conflict of interest resulting from such holdings due to our intent to profit from the liquidation of these shares . shares may be sold at any time , even after positive statements have been made regarding the above company . since we own shares , there is an inherent conflict of interest in our statements and opinions . readers of this publication are cautioned not to place undue reliance on forward - looking statements , which are based on certain assumptions and expectations involving various risks and uncertainties , that could cause results to differ materially from those set forth in the forward - looking statements . please be advised that nothing within this email shall constitute a solicitation or an invitation to get position in or sell any security mentioned herein . this newsletter is neither a registered investment advisor nor affiliated with any broker or dealer . this newsletter was paid $ 49000 from third party to send this report . all statements made are our express opinion only and should be treated as such . we may own , take position and sell any securities mentioned at any time . this report includes forward - looking statements within the meaning of the private securities litigation reform act of 1995 . these statements may include terms as projected speculative price expect , believe , may , will , soar move , undervalued and intend or similar terms . \""
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "email_to_classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1f291a77-7545-4a93-bd22-3909e1195bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing the text of the email to classify\n",
    "# 1. Convert the email text to lowercase, remove punctuation, and split into words\n",
    "email_text = email_to_classify.lower().translate(str.maketrans(\" \",\" \", string.punctuation)).split()\n",
    "# 2. Apply stemming to each word and remove stopwords\n",
    "email_text = [stemmer.stem(word) for word in email_text if word not in stopwords_set]\n",
    "# 3. Join the stemmed words back into a single string\n",
    "email_text = ' '.join(email_text)\n",
    "# 4. Create a corpus containing the preprocessed email text\n",
    "email_corpus = [email_text]\n",
    "# 5. Transform the email text into a feature vector using the same vectorizer as used for training data\n",
    "x_email = vectorizer.transform(email_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "54f730d9-adc0-4eae-ad81-e1d7ddcfcd51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1], dtype=int64)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicting the label of the email text using the trained classifier\n",
    "clf.predict(x_email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "153cf8c9-2e01-414a-a38e-bdd537e5739a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accessing the label of the 16th document in the DataFrame\n",
    "df.label_num.iloc[15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73197e9-5627-45c1-b8aa-c7a552420eb1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
